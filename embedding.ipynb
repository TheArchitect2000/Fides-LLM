{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f12d5499",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "Your markdown or comments here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f148578",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "USER_AGENT environment variable not set, consider setting it to identify your requests.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üî• OpenAI SDK version in this environment: 1.82.1\n",
      "Requirement already satisfied: openai in /opt/homebrew/lib/python3.10/site-packages (1.82.1)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /opt/homebrew/lib/python3.10/site-packages (from openai) (4.9.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /opt/homebrew/lib/python3.10/site-packages (from openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /opt/homebrew/lib/python3.10/site-packages (from openai) (0.28.1)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in /opt/homebrew/lib/python3.10/site-packages (from openai) (0.8.2)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in /opt/homebrew/lib/python3.10/site-packages (from openai) (2.11.4)\n",
      "Requirement already satisfied: sniffio in /opt/homebrew/lib/python3.10/site-packages (from openai) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in /opt/homebrew/lib/python3.10/site-packages (from openai) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in /Users/reza/Library/Python/3.10/lib/python/site-packages (from openai) (4.13.2)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /Users/reza/Library/Python/3.10/lib/python/site-packages (from anyio<5,>=3.5.0->openai) (1.2.2)\n",
      "Requirement already satisfied: idna>=2.8 in /opt/homebrew/lib/python3.10/site-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
      "Requirement already satisfied: certifi in /opt/homebrew/lib/python3.10/site-packages (from httpx<1,>=0.23.0->openai) (2025.4.26)\n",
      "Requirement already satisfied: httpcore==1.* in /opt/homebrew/lib/python3.10/site-packages (from httpx<1,>=0.23.0->openai) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in /opt/homebrew/lib/python3.10/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.16.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /opt/homebrew/lib/python3.10/site-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in /opt/homebrew/lib/python3.10/site-packages (from pydantic<3,>=1.9.0->openai) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /opt/homebrew/lib/python3.10/site-packages (from pydantic<3,>=1.9.0->openai) (0.4.0)\n",
      "‚úÖ OpenAI SDK version after upgrade: 1.82.1\n"
     ]
    }
   ],
   "source": [
    "# pip install selenium webdriver-manager\n",
    "# pip install --upgrade openai\n",
    "# pip install --upgrade openai\n",
    "\n",
    "import os\n",
    "import time\n",
    "import yt_dlp\n",
    "import openai\n",
    "\n",
    "from langchain_community.document_loaders import PyPDFLoader, YoutubeLoader, UnstructuredPowerPointLoader \n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_community.document_loaders import GitLoader\n",
    "from langchain_community.vectorstores import Chroma\n",
    "\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import WebDriverException, TimeoutException, StaleElementReferenceException\n",
    "\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "\n",
    "from urllib.parse import urljoin, urlparse\n",
    "\n",
    "print(\"üî• OpenAI SDK version in this environment:\", openai.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4c7ff266",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "# --- Step 2: Load environment variables from .env file\n",
    "os.environ[\"OPENAI_API_KEY\"] = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8cb49696",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Web Crawler 1 started ....\n",
      "Visited (1/53), Depth 0): https://fidesinnova.io/\n",
      "Visited (2/53), Depth 1): https://fidesinnova.io/devices/\n",
      "Visited (3/53), Depth 1): https://fidesinnova.io/courses/\n",
      "Visited (4/53), Depth 1): https://fidesinnova.io/Contacts\n",
      "Visited (5/53), Depth 1): https://fidesinnova.io/About\n",
      "Visited (6/53), Depth 1): https://fidesinnova.io/Contacts/\n",
      "Visited (7/53), Depth 1): https://fidesinnova.io/launch-your-iot-device-in-under-a-week-with-fidesinnova-platform-the-fast-track-to-market/\n",
      "Visited (8/53), Depth 1): https://fidesinnova.io/category/fidesinnova/\n",
      "Visited (9/53), Depth 1): https://fidesinnova.io/unlocking-the-power-of-digital-twins-in-smart-building-management/\n",
      "Visited (10/53), Depth 1): https://fidesinnova.io/data-monetization-in-the-fidesinnova-ecosystem-unlocking-new-revenue-streams/\n",
      "Visited (11/53), Depth 1): https://fidesinnova.io/blog-standard/\n",
      "Visited (12/53), Depth 2): https://fidesinnova.io/devices-ecardv2/\n",
      "Visited (13/53), Depth 2): https://fidesinnova.io/devices-zk-multisensor/\n",
      "Visited (14/53), Depth 2): https://fidesinnova.io/devices-ecardv1/\n",
      "Visited (15/53), Depth 2): https://fidesinnova.io/devices-minisensor\n",
      "Visited (16/53), Depth 2): https://fidesinnova.io/courses/course-1-zero-knowledge-proof-zkp-theory/\n",
      "Visited (17/53), Depth 2): https://fidesinnova.io/?page_id=/hramezan/\n",
      "Visited (18/53), Depth 2): https://fidesinnova.io/courses/course-2-zero-knowledge-proof-zkp-programming/\n",
      "Visited (19/53), Depth 2): https://fidesinnova.io/courses/course-3-internet-of-things-iot/\n",
      "Visited (20/53), Depth 2): https://fidesinnova.io/courses/course-4-blockly-programming-essentials/\n",
      "Visited (21/53), Depth 2): https://fidesinnova.io/category/blog/consensus_algorithms/\n",
      "Visited (22/53), Depth 2): https://fidesinnova.io/category/blog/decentralized_systems/\n",
      "Visited (23/53), Depth 2): https://fidesinnova.io/category/blog/iot/\n",
      "Visited (24/53), Depth 2): https://fidesinnova.io/category/blog/mesh_iot_network/\n",
      "Visited (25/53), Depth 2): https://fidesinnova.io/category/blog/mqtt/\n",
      "Visited (26/53), Depth 2): https://fidesinnova.io/category/service-contract/\n",
      "Visited (27/53), Depth 2): https://fidesinnova.io/category/blog/sharing_data/\n",
      "Visited (28/53), Depth 2): https://fidesinnova.io/tag/blockchain/\n",
      "Visited (29/53), Depth 2): https://fidesinnova.io/tag/building-digital-twin/\n",
      "Visited (30/53), Depth 2): https://fidesinnova.io/tag/consensus-algorithms/\n",
      "Visited (31/53), Depth 2): https://fidesinnova.io/tag/d2pos/\n",
      "Visited (32/53), Depth 2): https://fidesinnova.io/tag/data-monetization/\n",
      "Visited (33/53), Depth 2): https://fidesinnova.io/tag/decentralized-systems/\n",
      "Visited (34/53), Depth 2): https://fidesinnova.io/tag/iot/\n",
      "Visited (35/53), Depth 2): https://fidesinnova.io/tag/mesh-iot-network/\n",
      "Visited (36/53), Depth 2): https://fidesinnova.io/tag/miotn/\n",
      "Visited (37/53), Depth 2): https://fidesinnova.io/tag/mobile-app/\n",
      "Visited (38/53), Depth 2): https://fidesinnova.io/tag/mqtt/\n",
      "Visited (39/53), Depth 2): https://fidesinnova.io/tag/mqtts/\n",
      "Visited (40/53), Depth 2): https://fidesinnova.io/tag/proof-of-stake/\n",
      "Visited (41/53), Depth 2): https://fidesinnova.io/tag/service-contract/\n",
      "Visited (42/53), Depth 2): https://fidesinnova.io/tag/service-market/\n",
      "Visited (43/53), Depth 2): https://fidesinnova.io/tag/sharing-data/\n",
      "Visited (44/53), Depth 2): https://fidesinnova.io/tag/web3/\n",
      "Visited (45/53), Depth 2): https://fidesinnova.io/tag/web-app/\n",
      "Visited (46/53), Depth 2): https://fidesinnova.io/tag/zk-iot/\n",
      "Visited (47/53), Depth 2): https://fidesinnova.io/wp-login.php?action=lostpassword&redirect_to=https%3A%2F%2Ffidesinnova.io%2Fcourses%2Fcourse-1-zero-knowledge-proof-zkp-theory%2F\n",
      "Visited (48/53), Depth 2): https://fidesinnova.io/portfolio/in-the-jungle/\n",
      "Visited (49/53), Depth 2): https://fidesinnova.io/portfolio/stars-and-planets/\n",
      "Visited (50/53), Depth 2): https://fidesinnova.io/portfolio/the-tree-of-life/\n",
      "Visited (51/53), Depth 2): https://fidesinnova.io/portfolio/space-trip/\n",
      "Visited (52/53), Depth 2): https://fidesinnova.io/portfolio/eyes-dont-lie/\n",
      "Visited (53/53), Depth 2): https://fidesinnova.io/portfolio/aliens-watch-us/\n",
      "\n",
      " Total unique internal URLs visited: 53\n",
      "https://fidesinnova.io/category/blog/mqtt/ is loaded.\n",
      "https://fidesinnova.io/tag/web3/ is loaded.\n",
      "https://fidesinnova.io/portfolio/the-tree-of-life/ is loaded.\n",
      "https://fidesinnova.io/tag/mqtt/ is loaded.\n",
      "https://fidesinnova.io/tag/web-app/ is loaded.\n",
      "https://fidesinnova.io/?page_id=/hramezan/ is loaded.\n",
      "https://fidesinnova.io/portfolio/space-trip/ is loaded.\n",
      "https://fidesinnova.io/category/blog/consensus_algorithms/ is loaded.\n",
      "https://fidesinnova.io/About is loaded.\n",
      "https://fidesinnova.io/unlocking-the-power-of-digital-twins-in-smart-building-management/ is loaded.\n",
      "https://fidesinnova.io/devices-minisensor is loaded.\n",
      "https://fidesinnova.io/portfolio/in-the-jungle/ is loaded.\n",
      "https://fidesinnova.io/tag/proof-of-stake/ is loaded.\n",
      "https://fidesinnova.io/tag/iot/ is loaded.\n",
      "https://fidesinnova.io/portfolio/aliens-watch-us/ is loaded.\n",
      "https://fidesinnova.io/tag/building-digital-twin/ is loaded.\n",
      "https://fidesinnova.io/devices-ecardv2/ is loaded.\n",
      "https://fidesinnova.io/category/blog/sharing_data/ is loaded.\n",
      "https://fidesinnova.io/courses/course-1-zero-knowledge-proof-zkp-theory/ is loaded.\n",
      "https://fidesinnova.io/courses/ is loaded.\n",
      "https://fidesinnova.io/devices-ecardv1/ is loaded.\n",
      "https://fidesinnova.io/tag/miotn/ is loaded.\n",
      "https://fidesinnova.io/tag/mqtts/ is loaded.\n",
      "https://fidesinnova.io/tag/mobile-app/ is loaded.\n",
      "https://fidesinnova.io/courses/course-3-internet-of-things-iot/ is loaded.\n",
      "https://fidesinnova.io/tag/service-market/ is loaded.\n",
      "https://fidesinnova.io/courses/course-2-zero-knowledge-proof-zkp-programming/ is loaded.\n",
      "https://fidesinnova.io/category/service-contract/ is loaded.\n",
      "https://fidesinnova.io/portfolio/eyes-dont-lie/ is loaded.\n",
      "https://fidesinnova.io/blog-standard/ is loaded.\n",
      "https://fidesinnova.io/tag/decentralized-systems/ is loaded.\n",
      "https://fidesinnova.io/category/fidesinnova/ is loaded.\n",
      "https://fidesinnova.io/portfolio/stars-and-planets/ is loaded.\n",
      "https://fidesinnova.io/Contacts/ is loaded.\n",
      "https://fidesinnova.io/tag/blockchain/ is loaded.\n",
      "https://fidesinnova.io/tag/data-monetization/ is loaded.\n",
      "https://fidesinnova.io/devices/ is loaded.\n",
      "https://fidesinnova.io/tag/mesh-iot-network/ is loaded.\n",
      "https://fidesinnova.io/wp-login.php?action=lostpassword&redirect_to=https%3A%2F%2Ffidesinnova.io%2Fcourses%2Fcourse-1-zero-knowledge-proof-zkp-theory%2F is loaded.\n",
      "https://fidesinnova.io/tag/consensus-algorithms/ is loaded.\n",
      "https://fidesinnova.io/category/blog/iot/ is loaded.\n",
      "https://fidesinnova.io/tag/sharing-data/ is loaded.\n",
      "https://fidesinnova.io/launch-your-iot-device-in-under-a-week-with-fidesinnova-platform-the-fast-track-to-market/ is loaded.\n",
      "https://fidesinnova.io/tag/d2pos/ is loaded.\n",
      "https://fidesinnova.io/data-monetization-in-the-fidesinnova-ecosystem-unlocking-new-revenue-streams/ is loaded.\n",
      "https://fidesinnova.io/category/blog/decentralized_systems/ is loaded.\n",
      "https://fidesinnova.io/tag/service-contract/ is loaded.\n",
      "https://fidesinnova.io/Contacts is loaded.\n",
      "https://fidesinnova.io/courses/course-4-blockly-programming-essentials/ is loaded.\n",
      "https://fidesinnova.io/category/blog/mesh_iot_network/ is loaded.\n",
      "https://fidesinnova.io/tag/zk-iot/ is loaded.\n",
      "https://fidesinnova.io/ is loaded.\n",
      "https://fidesinnova.io/devices-zk-multisensor/ is loaded.\n"
     ]
    }
   ],
   "source": [
    "# WEB CRAWLER\n",
    "print(\"Web Crawler 1 started ....\")\n",
    "\n",
    "def crawl_internal_links(start_url, max_pages=50, max_depth=1):\n",
    "    \"\"\"\n",
    "    Crawl internal URLs from a site using Selenium, with support for JavaScript-heavy pages.\n",
    "\n",
    "    Args:\n",
    "        start_url (str): The URL to start crawling from.\n",
    "        max_pages (int): Max number of pages to crawl.\n",
    "        max_depth (int): Max depth to crawl (0 = just root).\n",
    "\n",
    "    Returns:\n",
    "        list: A list of internal URLs that were successfully visited.\n",
    "    \"\"\"\n",
    "    # Selenium Headless Browser Setup\n",
    "    options = Options()\n",
    "    options.add_argument(\"--headless=new\")\n",
    "    options.add_argument(\"--disable-gpu\")\n",
    "    options.add_argument(\"--no-sandbox\")\n",
    "    options.add_argument(\"--disable-dev-shm-usage\")\n",
    "    driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()), options=options)\n",
    "\n",
    "    visited = set()\n",
    "    domain = urlparse(start_url).netloc\n",
    "    to_visit = [(start_url, 0)]\n",
    "\n",
    "    while to_visit and len(visited) < max_pages:\n",
    "        url, depth = to_visit.pop(0)\n",
    "        if url in visited or depth > max_depth:\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            driver.get(url)\n",
    "            WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.TAG_NAME, \"a\")))\n",
    "            time.sleep(1)  # üîÅ Wait for JS to load\n",
    "\n",
    "            print(f\"Visited ({len(visited)+1}/{max_pages}), Depth {depth}): {url}\")\n",
    "            visited.add(url)\n",
    "\n",
    "            # If max depth reached, skip link extraction\n",
    "            if depth == max_depth:\n",
    "                continue\n",
    "\n",
    "            # Extract and queue internal links\n",
    "            links = driver.find_elements(By.TAG_NAME, \"a\")\n",
    "            for link in links:\n",
    "                try:\n",
    "                    href = link.get_attribute(\"href\")\n",
    "                    if not href or href.startswith((\"mailto:\", \"tel:\", \"javascript:\")):\n",
    "                        continue\n",
    "\n",
    "                    parsed = urlparse(href)\n",
    "                    if parsed.netloc == domain or parsed.netloc == \"\":\n",
    "                        full_url = urljoin(url, href).split(\"#\")[0]\n",
    "                        if full_url not in visited and all(full_url != q[0] for q in to_visit):\n",
    "                            to_visit.append((full_url, depth + 1))\n",
    "                except StaleElementReferenceException:\n",
    "                    continue\n",
    "\n",
    "        except (WebDriverException, TimeoutException):\n",
    "            print(f\"‚ö†Ô∏è Skipping (Error): {url}\")\n",
    "            visited.add(url)\n",
    "            continue\n",
    "\n",
    "    driver.quit()\n",
    "\n",
    "    # Print summary\n",
    "    print(f\"\\n Total unique internal URLs visited: {len(visited)}\")\n",
    "\n",
    "    if len(visited) < max_pages:\n",
    "        print(\"‚ö†Ô∏è Number of crawled URLs is less than max_pages. Possible reasons:\")\n",
    "        print(\"- Site may not have enough unique pages within the allowed depth.\")\n",
    "        print(\"- Some links might be hidden behind JavaScript interactions.\")\n",
    "        print(\"- Some links could be blocked, inaccessible, or slow-loading.\")\n",
    "        print(\"- Your max_depth may be too shallow to discover deeper links, try changing depth.\")\n",
    "    \n",
    "    return list(visited)\n",
    "\n",
    "#### CONFIGURABLE SETTINGS \n",
    "start_url = \"https://fidesinnova.io/\"\n",
    "max_pages = 53   # Maximum number of pages to visit\n",
    "max_depth = 2    # 0 = only root, 1 = root + links from root\n",
    "\n",
    "####  Run the Crawler\n",
    "web_docs_list1 = crawl_internal_links(start_url, max_pages, max_depth)\n",
    "\n",
    "#  Load the web documents\n",
    "web_docs1 = []\n",
    "for idx in web_docs_list1:\n",
    "    a = WebBaseLoader(idx)\n",
    "    try:\n",
    "        web_docs1.extend(a.load())\n",
    "        print(idx + \" is loaded.\")\n",
    "    except:\n",
    "        print(f\"{idx} is not loaded.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55a3a276",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Web Crawler 2 started ....\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"Web Crawler 2 started ....\")\n",
    "\n",
    "# Headless setup\n",
    "options = Options()\n",
    "options.add_argument(\"--headless=new\")\n",
    "options.add_argument(\"--disable-gpu\")\n",
    "options.add_argument(\"--no-sandbox\")\n",
    "options.add_argument(\"--disable-dev-shm-usage\")\n",
    "options.add_argument(\"--window-size=1920,1080\")\n",
    "options.add_argument(\"--log-level=3\")\n",
    "options.add_argument(\"--disable-blink-features=AutomationControlled\")\n",
    "\n",
    "driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()), options=options)\n",
    "\n",
    "base_url = \"https://www.fidesinnova.io/\"\n",
    "visited = set()\n",
    "web_docs_list2 = set()\n",
    "\n",
    "def is_valid_internal(url):\n",
    "    parsed = urlparse(url)\n",
    "    return parsed.scheme in [\"http\", \"https\"] and parsed.netloc.endswith(\"fidesinnova.io\")\n",
    "\n",
    "def crawl(url):\n",
    "    if url in visited:\n",
    "        return\n",
    "    visited.add(url)\n",
    "\n",
    "    try:\n",
    "        driver.get(url)\n",
    "        time.sleep(2)  # Let dynamic content load\n",
    "\n",
    "        links = driver.find_elements(\"tag name\", \"a\")\n",
    "        for link in links:\n",
    "            href = link.get_attribute(\"href\")\n",
    "            if href:\n",
    "                full_url = urljoin(url, href.split(\"#\")[0])  # remove fragments\n",
    "                if is_valid_internal(full_url) and full_url not in web_docs_list2:\n",
    "                    web_docs_list2.add(full_url)\n",
    "                    crawl(full_url)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error visiting {url}: {e}\")\n",
    "\n",
    "# Start\n",
    "crawl(base_url)\n",
    "\n",
    "driver.quit()\n",
    "\n",
    "# Output\n",
    "print(\"\\n=== Discovered Internal URLs ===\")\n",
    "for url in sorted(web_docs_list2):\n",
    "    print(url)\n",
    "print(f\"\\nTotal internal URLs web_docs_list2: {len(web_docs_list2)}\")\n",
    "\n",
    "\n",
    "#  Load the web documents\n",
    "web_docs2 = []\n",
    "for idx in web_docs_list2:\n",
    "    a = WebBaseLoader(idx)\n",
    "    try:\n",
    "        web_docs2.extend(a.load())\n",
    "        print(idx + \" is loaded.\")\n",
    "    except:\n",
    "        print(f\"{idx} is not loaded.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e08b9305",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Access the token\n",
    "# GITHUB_TOKEN = os.getenv(\"GITHUB_TOKEN\")\n",
    "\n",
    "# HEADERS = {\n",
    "#     \"User-Agent\": \"Mozilla/5.0\",\n",
    "#     \"Accept\": \"application/vnd.github.v3+json\",\n",
    "#     \"Authorization\": f\"token {GITHUB_TOKEN}\"\n",
    "# }\n",
    "\n",
    "# readable_extensions = {\n",
    "#     \".py\", \".json\", \".html\", \".js\", \".ts\", \".css\", \".java\",\n",
    "#     \".c\", \".cpp\", \".rs\", \".txt\", \".md\", \".yml\", \".yaml\", \".sh\"\n",
    "# }\n",
    "\n",
    "# def is_readable_file(filename):\n",
    "#     return any(filename.endswith(ext) for ext in readable_extensions)\n",
    "\n",
    "# def get_default_branch(owner, repo):\n",
    "#     url = f\"https://api.github.com/repos/{owner}/{repo}\"\n",
    "#     try:\n",
    "#         response = requests.get(url, headers=HEADERS, timeout=10)\n",
    "#         if response.status_code == 200:\n",
    "#             return response.json().get(\"default_branch\", \"main\")\n",
    "#         else:\n",
    "#             print(f\"‚ùå Failed to get default branch for {owner}/{repo} ({response.status_code})\")\n",
    "#             return \"main\"\n",
    "#     except requests.exceptions.RequestException as e:\n",
    "#         print(f\"‚ùå Exception getting default branch for {owner}/{repo}: {e}\")\n",
    "#         return \"main\"\n",
    "\n",
    "# def list_files_from_api(owner, repo, branch, path=\"\", depth=0, max_depth=10):\n",
    "#     url = f\"https://api.github.com/repos/{owner}/{repo}/contents/{path}?ref={branch}\"\n",
    "#     try:\n",
    "#         response = requests.get(url, headers=HEADERS, timeout=15)\n",
    "#     except requests.exceptions.RequestException as e:\n",
    "#         print(f\"‚ùå Exception accessing {url}: {e}\")\n",
    "#         return []\n",
    "\n",
    "#     if response.status_code == 403:\n",
    "#         print(f\"‚ùå Rate limit hit or access denied for: {url}\")\n",
    "#         return []\n",
    "#     elif response.status_code != 200:\n",
    "#         print(f\"‚ùå Failed to access: {url} ({response.status_code})\")\n",
    "#         return []\n",
    "\n",
    "#     items = response.json()\n",
    "#     files = []\n",
    "\n",
    "#     # Defensive: sometimes API returns a dict on error\n",
    "#     if isinstance(items, dict) and items.get(\"message\"):\n",
    "#         print(f\"‚ùå API error at {url}: {items['message']}\")\n",
    "#         return []\n",
    "\n",
    "#     for item in items:\n",
    "#         if item[\"type\"] == \"file\":\n",
    "#             filename = item[\"name\"]\n",
    "#             if is_readable_file(filename):\n",
    "#                 files.append(item[\"path\"])\n",
    "#         elif item[\"type\"] == \"dir\" and depth < max_depth:\n",
    "#             # Debug print to track recursion progress:\n",
    "#             print(f\"üîç Exploring directory: {item['path']} (depth {depth+1})\")\n",
    "#             files += list_files_from_api(owner, repo, branch, item[\"path\"], depth+1, max_depth)\n",
    "\n",
    "#     return files\n",
    "\n",
    "# github_repos = [\n",
    "#     \"TheArchitect2000/Fides-Innova-WiKi\",\n",
    "#     \"TheArchitect2000/Blockchain-based-IoT-Server\",\n",
    "#     \"TheArchitect2000/ZKP-IoT-Arm-Siemens-IoT2050-C\",\n",
    "#     \"TheArchitect2000/zkiot-riscv-qemu-c\", \n",
    "#     \"TheArchitect2000/Fides-Innova-Smart-Contract-Protocol\",\n",
    "#     \"TheArchitect2000/ZKP-Blockchain-Explorer\",\n",
    "#     \"TheArchitect2000/evm-server\",\n",
    "#     \"TheArchitect2000/New-IoT-Device-Integration\",\n",
    "#     \"TheArchitect2000/zkiot-riscv-qemu-rust\"\n",
    "# ]\n",
    "\n",
    "# github_docs = set()\n",
    "# for full_name in github_repos:\n",
    "#     owner, repo = full_name.split(\"/\")\n",
    "#     print(f\"\\nüì¶ Crawling repository: {full_name}\")\n",
    "#     default_branch = get_default_branch(owner, repo)\n",
    "#     files = list_files_from_api(owner, repo, default_branch)\n",
    "#     if files:\n",
    "#         print(f\"‚úÖ Found {len(files)} readable files:\")\n",
    "#         for f in files:\n",
    "#             t1 = f\"https://github.com/{full_name}/blob/main/{f}\"\n",
    "#             print(\"   -\", t1)\n",
    "#             github_docs.add(t1)\n",
    "#     else:\n",
    "#         print(\"‚ö†Ô∏è No readable files found or repo is empty/private.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "104e22c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"GitHub Crawler started ....\")\n",
    "\n",
    "# loading GitHub Repos\n",
    "github_repos = [\n",
    "    \"https://github.com/TheArchitect2000/Fides-Innova-WiKi\",\n",
    "    \"https://github.com/TheArchitect2000/Blockchain-based-IoT-Server\",\n",
    "    \"https://github.com/TheArchitect2000/ZKP-IoT-Arm-Siemens-IoT2050-C\",\n",
    "    \"https://github.com/TheArchitect2000/zkiot-riscv-qemu-c\", \n",
    "    \"https://github.com/TheArchitect2000/Fides-Innova-Smart-Contract-Protocol\",\n",
    "    \"https://github.com/TheArchitect2000/ZKP-Blockchain-Explorer\",\n",
    "    \"https://github.com/TheArchitect2000/evm-server\",\n",
    "    \"https://github.com/TheArchitect2000/New-IoT-Device-Integration\",\n",
    "    \"https://github.com/TheArchitect2000/zkiot-riscv-qemu-rust\"\n",
    "]\n",
    "\n",
    "github_docs = []\n",
    "\n",
    "\n",
    "for url in github_repos:\n",
    "    print(f\"üì• Loading repository: {url}\")\n",
    "    repo_name = url.split(\"/\")[-1]\n",
    "    local_path = f\"./cloned_repos/{repo_name}\"\n",
    "\n",
    "    loader = GitLoader(\n",
    "        repo_path=local_path,\n",
    "        clone_url=url,\n",
    "        branch=\"main\",\n",
    "        file_filter=lambda f: f.endswith((\n",
    "            \".py\", \".md\", \".c\", \".cpp\", \".rs\", \".json\", \".html\",\n",
    "            \".js\", \".ts\", \".css\", \".java\", \".txt\", \".yml\", \".yaml\", \".sh\"\n",
    "        ))\n",
    "    )\n",
    "    \n",
    "    github_docs = loader.load()\n",
    "    print(f\"‚úÖ Loaded {len(github_docs)} documents from {repo_name}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ef84b32",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"YouTube Crawler started ....\")\n",
    "\n",
    "# Fides Innova YouTube Channel ID\n",
    "CHANNEL_ID = \"UCrrqGYx98H1dPdZsNb1i9-g\"\n",
    "CHANNEL_URL = f\"https://www.youtube.com/channel/{CHANNEL_ID}\"\n",
    "\n",
    "def fetch_video_urls(channel_url: str):\n",
    "    ydl_opts = {\n",
    "        'ignoreerrors': True,\n",
    "        'quiet': True,\n",
    "        'extract_flat': True,  # Only metadata, not downloading\n",
    "        'force_generic_extractor': False,\n",
    "    }\n",
    "\n",
    "    with yt_dlp.YoutubeDL(ydl_opts) as ydl:\n",
    "        result = ydl.extract_info(channel_url, download=False)\n",
    "        video_urls = []\n",
    "        video_ids = []\n",
    "\n",
    "        if 'entries' in result:\n",
    "            for entry in result['entries']:\n",
    "                if entry and 'id' in entry:\n",
    "                    video_url = f\"https://www.youtube.com/watch?v={entry['id']}\"\n",
    "                    video_urls.append(video_url)\n",
    "                    video_ids.append(entry['id'])\n",
    "        return video_ids\n",
    "\n",
    "# Fetch and display video URLs\n",
    "video_ids = fetch_video_urls(CHANNEL_URL)\n",
    "print(f\"‚úÖ Found {len(video_ids)} videos on channel.\\n\")\n",
    "\n",
    "youtube_docs = []\n",
    "second_try_idx = []\n",
    "third_try_idx = []\n",
    "for idx in video_ids:\n",
    "    a = YoutubeLoader(idx)\n",
    "    try:\n",
    "        youtube_docs.extend(a.load())\n",
    "        print(idx + \" is loaded.\")\n",
    "    except:\n",
    "        print(f\"{idx} is not loaded.\")\n",
    "        second_try_idx.append(str(idx))\n",
    "        print(\"\\n unloaded list \")\n",
    "        print(second_try_idx)\n",
    "        print(\"\\n\")\n",
    "\n",
    "print(\"\\n\")\n",
    "print(\"second try for unloded videos.\")\n",
    "\n",
    "for idx in second_try_idx:\n",
    "    print(\"waiting 10 seconds...\")\n",
    "    time.sleep(10)\n",
    "    a = YoutubeLoader(idx)\n",
    "    try:\n",
    "        youtube_docs.extend(a.load())\n",
    "        print(idx + \" is loaded in the second try.\")\n",
    "    except:\n",
    "        print(\"\\n\")\n",
    "        print(f\"{idx} is not loaded in the second try.\")\n",
    "        third_try_idx.append(str(idx))\n",
    "        print(\"\\n unloaded list for the second time \")\n",
    "        print(second_try_idx)\n",
    "        print(\"\\n\")\n",
    "\n",
    "def change_YouTube_doc(doc):\n",
    "    doc.metadata['type']='YouTube'\n",
    "    return doc\n",
    "\n",
    "youtube_docs = list(map(change_YouTube_doc, youtube_docs))\n",
    "\n",
    "print(\"=== ALL youtube videos ===)\")\n",
    "print(len(youtube_docs))\n",
    "print(\"=== Loaded youtube videos ===)\")\n",
    "print(len(youtube_docs)-len(third_try_idx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8aa2846",
   "metadata": {},
   "outputs": [],
   "source": [
    "youtube_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59179ece",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Step 6: Load PDFs ---\n",
    "print(\"PDF Crawler started ....\")\n",
    "\n",
    "pdf_docs = []\n",
    "pdf_files = [\n",
    "    \"PDF/zkIoT.pdf\",\n",
    "]\n",
    "\n",
    "for path in pdf_files:\n",
    "    try:\n",
    "        loader = PyPDFLoader(path)\n",
    "        pdf_docs.extend(loader.load())\n",
    "        print(len(pdf_docs))\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading PDF {path}: {e}\")\n",
    "\n",
    "def change_pdf_doc(doc):\n",
    "    doc.metadata['type']='PDF'\n",
    "    return doc\n",
    "\n",
    "pdf_docs = list(map(change_pdf_doc, pdf_docs))\n",
    "\n",
    "print(\"=== ALL PDF docs ===)\")\n",
    "print(len(pdf_docs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba0a3c8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c735c2b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Step 6: Load PDFs ---\n",
    "print(\"PPTX Crawler started ....\")\n",
    "\n",
    "pptx_docs = []\n",
    "pptx_files = [\n",
    "    \"PPTX/FidesinnovaDeck-v11.pptx\"\n",
    "]\n",
    "\n",
    "for path in pptx_files:\n",
    "    try:\n",
    "        loader = UnstructuredPowerPointLoader(path)\n",
    "        pptx_docs.extend(loader.load())\n",
    "        print(f\"‚úÖ Loaded: {path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error loading PPTX {path}: {e}\")\n",
    "\n",
    "# Add metadata\n",
    "def change_pptx_doc(doc):\n",
    "    doc.metadata['type'] = 'PPTX'\n",
    "    return doc\n",
    "\n",
    "pptx_docs = list(map(change_pptx_doc, pptx_docs))\n",
    "\n",
    "print(\"=== ALL PPTX docs ===)\")\n",
    "print(len(pptx_docs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "729394a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "pptx_docs\n",
    "splitter = RecursiveCharacterTextSplitter(chunk_size = 1000, chunk_overlap = 100)\n",
    "split_pptx_docs = splitter.split_documents(pptx_docs)\n",
    "embedding = OpenAIEmbeddings(model=\"text-embedding-3-large\")\n",
    "vectordb = Chroma(\n",
    "    collection_name=\"fides_crawled_data\",\n",
    "    embedding_function=embedding,\n",
    "    persist_directory=\"./chroma_langchain_db\"\n",
    ")\n",
    "vectordb.add_documents(pptx_docs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e55ede9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Step 7: Split & Vectorize ---\n",
    "print(\"Splitter and db started ....\")\n",
    "# all_docs =  youtube_docs + pdf_docs + pptx_docs + web_docs1 + web_docs2 + github_docs\n",
    "\n",
    "splitter = RecursiveCharacterTextSplitter(chunk_size = 1000, chunk_overlap = 100)\n",
    "print(\"Splitting youtube_docs ...\")\n",
    "split_youtube_docs = splitter.split_documents(youtube_docs)\n",
    "print(\"Splitting pdf_docs ...\")\n",
    "split_pdf_docs = splitter.split_documents(pdf_docs)\n",
    "print(\"Splitting pptx_docs ...\")\n",
    "split_pptx_docs = splitter.split_documents(pptx_docs)\n",
    "print(\"Splitting web_docs1 ...\")\n",
    "split_web_docs1 = splitter.split_documents(web_docs1)\n",
    "print(\"Splitting web_docs2 ...\")\n",
    "split_web_docs2 = splitter.split_documents(web_docs2)\n",
    "print(\"Splitting github_docs ...\")\n",
    "split_github_docs = splitter.split_documents(github_docs)\n",
    "\n",
    "embedding = OpenAIEmbeddings(model=\"text-embedding-3-large\")\n",
    "vectordb = Chroma(\n",
    "    collection_name=\"fides_crawled_data\",\n",
    "    embedding_function=embedding,\n",
    "    persist_directory=\"./chroma_langchain_db\"\n",
    ")\n",
    "\n",
    "print(\"Starting split_youtube_docs ...\")\n",
    "vectordb.add_documents(split_youtube_docs)\n",
    "\n",
    "print(\"Adding split_pdf_docs ...\")\n",
    "vectordb.add_documents(split_pdf_docs)\n",
    "\n",
    "#######################\n",
    "print(\"Adding split_pptx_docs ...\")\n",
    "vectordb.add_documents(split_pptx_docs)\n",
    "\n",
    "#########################\n",
    "print(\"Adding split_web_docs1 ...\")\n",
    "vectordb.add_documents(split_web_docs1)\n",
    "\n",
    "print(\"Adding split_web_docs2 ...\")\n",
    "vectordb.add_documents(split_web_docs2)\n",
    "\n",
    "print(\"Adding split_github_docs ...\")\n",
    "# Instead of adding GitHun large documents using:\n",
    "# vectordb.add_documents(split_github_docs)\n",
    "# we do this:\n",
    "batch_size = 100 \n",
    "for i in range(0, len(split_github_docs), batch_size):\n",
    "    batch = split_github_docs[i:i + batch_size]\n",
    "    vectordb.add_documents(batch)\n",
    "    print(f\"‚úÖ Added batch {i // batch_size + 1} of {len(split_github_docs)/batch_size} documents\")\n",
    "\n",
    "print(\"‚úÖ All documents crawled, split, and stored in vector DB.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0f70d9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"DB size: {len(vectordb)}\")"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
