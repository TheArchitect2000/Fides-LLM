{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f12d5499",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "Your markdown or comments here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cb49696",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"embedding-crawler.ipynb\n",
    "\n",
    "Automatically generated by Colab.\n",
    "\n",
    "Original file is located at\n",
    "    https://colab.research.google.com/drive/1veoXGbqXGOxHJrYH6ZehSCyoLBhXvML9\n",
    "\"\"\"\n",
    "\n",
    "# for embedding.py file\n",
    "# python3 -m venv venv\n",
    "# source venv/bin/activate\n",
    "# pip install python-dotenv langchain_openai langchain_community chromadb youtube-transcript-api pytube pypdf web3 SpeechRecognition opencv-python\n",
    "# python3 embedding.py\n",
    "\n",
    "%pip install --upgrade pip -q\n",
    "%pip install python-dotenv langchain_openai langchain_community chromadb youtube-transcript-api pytube pypdf web3 -q\n",
    "%pip install youtube-transcript-api bs4 pypdf -q\n",
    "%pip install SpeechRecognition -q\n",
    "%pip install opencv-python -q\n",
    "%pip install beautifulsoup4 -q\n",
    "%pip install python-pptx -q\n",
    "%pip install 'unstructured[all]' -q\n",
    "\n",
    "## For mac\n",
    "# brew install libmagic\n",
    "# brew install file\n",
    "\n",
    "## For Ubuntu\n",
    "# sudo apt-get update\n",
    "# sudo apt-get install libmagic1 libmagic-dev\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15bb0691",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# --- Step 1: \n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import time\n",
    "import requests\n",
    "import yt_dlp\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "from langchain_community.document_loaders import PyPDFLoader, YoutubeLoader\n",
    "from langchain_core.documents import Document\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_community.document_loaders import UnstructuredPowerPointLoader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1731a1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Step 2: Load environment variables from .env file\n",
    "load_dotenv()\n",
    "os.environ[\"OPENAI_API_KEY\"] = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55a3a276",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Step 3: Web crawler\n",
    "headers = {\n",
    "    \"User-Agent\": \"Mozilla/5.0 (compatible; FidesCrawler/1.0)\"\n",
    "}\n",
    "\n",
    "web_urls = [\n",
    "    \"https://www.fidesinnova.io/\",\n",
    "    \"https://fidesinnova.io/devices/\",\n",
    "    \"https://fidesinnova.io/Contacts/\",\n",
    "    \"https://fidesinnova.io/courses/\",\n",
    "    \"https://linktr.ee/fidesinnova/\",\n",
    "    \"https://play.google.com/store/apps/details?id=io.fidesinnova.front&pli=1/\",\n",
    "    \"https://fidesinnova.io/blog-standard/\",\n",
    "    \"https://fidesinnova.io/About/\",\n",
    "    \"https://fidesinnova.io/#articles/\",\n",
    "    \"https://discord.com/invite/NQdM6JGwcs/\",\n",
    "    \"https://fidesinnova.io/service-market/\",\n",
    "    \"https://fidesinnova.io/service-contract-2/\",\n",
    "    \"https://fidesinnova.io/d2pos/\",\n",
    "    \"https://fidesinnova.io/web3/\",\n",
    "    \"https://fidesinnova.io/service-contract/\",\n",
    "    \"https://fidesinnova.io/miotn/\",\n",
    "    \"https://fidesinnova.io/consensus-algorithms/\",\n",
    "    \"https://fidesinnova.io/mqtt-mqtts/\",\n",
    "    \"https://explorer.fidesinnova.io/\",\n",
    "    \"https://apps.apple.com/ca/app/fidesinnova/id6477492757/\",\n",
    "    \"https://www.youtube.com/@FidesInnova/playlists/\",\n",
    "    \"https://x.com/FidesInnova/\"\n",
    "\n",
    "]\n",
    "\n",
    "def crawl_web_url(url):\n",
    "    try:\n",
    "        response = requests.get(url, headers=headers, timeout=10)\n",
    "        response.raise_for_status()\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "        title = soup.title.string.strip() if soup.title else \"No Title\"\n",
    "        text = soup.get_text(separator='\\n', strip=True)\n",
    "        return Document(page_content=text, metadata={\"source\": url, \"title\": title, \"type\": \"Web\"})\n",
    "    except Exception as e:\n",
    "        print(f\"Error crawling {url}: {e}\")\n",
    "        return None\n",
    "\n",
    "web_docs = [doc for url in web_urls if (doc := crawl_web_url(url))]\n",
    "print(\"=== ALL web_docs ===)\")\n",
    "print(len(web_docs))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d0f9e3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Step 4: GitHub Crawler ---\n",
    "github_urls = [\n",
    "    \"https://github.com/TheArchitect2000/Fides-Innova-WiKi/\",\n",
    "    \"https://github.com/TheArchitect2000/Blockchain-based-IoT-Server\",\n",
    "    \"https://github.com/TheArchitect2000/ZKP-IoT-Arm-Siemens-IoT2050-C\",\n",
    "    \"https://github.com/TheArchitect2000/zkiot-riscv-qemu-c\",\n",
    "    \"https://github.com/TheArchitect2000/Fides-Innova-Smart-Contract-Protocol\",\n",
    "    \"https://github.com/TheArchitect2000/ZKP-Blockchain-Explorer\",\n",
    "    \"https://github.com/TheArchitect2000/evm-server\",\n",
    "    \"https://github.com/TheArchitect2000/New-IoT-Device-Integration\",\n",
    "    \"https://github.com/TheArchitect2000/zkiot-riscv-qemu-rust\"    \n",
    "]\n",
    "\n",
    "def crawl_github_url(url):\n",
    "    \n",
    "    headers = {\n",
    "    \"User-Agent\": \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 \"\n",
    "                    \"(KHTML, like Gecko) Chrome/123.0.0.0 Safari/537.36\"\n",
    "    }\n",
    "\n",
    "    try:\n",
    "        response = requests.get(url, headers=headers, timeout=10)\n",
    "        response.raise_for_status()\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "        title = soup.title.string.strip() if soup.title else \"No Title\"\n",
    "        text = soup.get_text(separator='\\n', strip=True)\n",
    "        return Document(page_content=text, metadata={\"source\": url, \"title\": title, \"type\": \"Web\"})\n",
    "    except Exception as e:\n",
    "        print(f\"Error crawling GitHub {url}: {e}\")\n",
    "        return None\n",
    "\n",
    "github_docs = [doc for url in github_urls if (doc := crawl_github_url(url))]\n",
    "\n",
    "print(\"=== ALL github_docs ===)\")\n",
    "print(len(github_docs))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ef84b32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Step 5: YouTube Channel Crawler ---\n",
    "\n",
    "# Fides Innova YouTube Channel ID\n",
    "CHANNEL_ID = \"UCrrqGYx98H1dPdZsNb1i9-g\"\n",
    "CHANNEL_URL = f\"https://www.youtube.com/channel/{CHANNEL_ID}\"\n",
    "\n",
    "def fetch_video_urls(channel_url: str):\n",
    "    ydl_opts = {\n",
    "        'ignoreerrors': True,\n",
    "        'quiet': True,\n",
    "        'extract_flat': True,  # Only metadata, not downloading\n",
    "        'force_generic_extractor': False,\n",
    "    }\n",
    "\n",
    "    with yt_dlp.YoutubeDL(ydl_opts) as ydl:\n",
    "        result = ydl.extract_info(channel_url, download=False)\n",
    "        video_urls = []\n",
    "        video_ids = []\n",
    "\n",
    "        if 'entries' in result:\n",
    "            for entry in result['entries']:\n",
    "                if entry and 'id' in entry:\n",
    "                    video_url = f\"https://www.youtube.com/watch?v={entry['id']}\"\n",
    "                    video_urls.append(video_url)\n",
    "                    video_ids.append(entry['id'])\n",
    "        return video_ids\n",
    "\n",
    "# Fetch and display video URLs\n",
    "video_ids = fetch_video_urls(CHANNEL_URL)\n",
    "print(f\"✅ Found {len(video_ids)} videos on channel.\\n\")\n",
    "\n",
    "youtube_docs = []\n",
    "second_try_idx = []\n",
    "third_try_idx = []\n",
    "for idx in video_ids:\n",
    "    a = YoutubeLoader(idx)\n",
    "    try:\n",
    "        youtube_docs.extend(a.load())\n",
    "        print(idx + \" is loaded.\")\n",
    "    except:\n",
    "        print(f\"{idx} is not loaded.\")\n",
    "        second_try_idx.append(str(idx))\n",
    "        print(\"\\n unloaded list \")\n",
    "        print(second_try_idx)\n",
    "        print(\"\\n\")\n",
    "\n",
    "print(\"\\n\")\n",
    "print(\"second try for unloded videos.\")\n",
    "\n",
    "for idx in second_try_idx:\n",
    "    print(\"waiting 10 seconds...\")\n",
    "    time.sleep(10)\n",
    "    a = YoutubeLoader(idx)\n",
    "    try:\n",
    "        youtube_docs.extend(a.load())\n",
    "        print(idx + \" is loaded in the second try.\")\n",
    "    except:\n",
    "        print(\"\\n\")\n",
    "        print(f\"{idx} is not loaded in the second try.\")\n",
    "        third_try_idx.append(str(idx))\n",
    "        print(\"\\n unloaded list for the second time \")\n",
    "        print(second_try_idx)\n",
    "        print(\"\\n\")\n",
    "\n",
    "def change_YouTube_doc(doc):\n",
    "    doc.metadata['type']='YouTube'\n",
    "    return doc\n",
    "\n",
    "youtube_docs = list(map(change_YouTube_doc, youtube_docs))\n",
    "\n",
    "print(\"=== ALL youtube videos ===)\")\n",
    "print(len(youtube_docs))\n",
    "print(\"=== Loaded youtube videos ===)\")\n",
    "print(len(youtube_docs)-len(third_try_idx))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59179ece",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Step 6: Load PDFs ---\n",
    "pdf_docs = []\n",
    "pdf_files = [\n",
    "    \"PDF/zkIoT.pdf\",\n",
    "]\n",
    "\n",
    "for path in pdf_files:\n",
    "    try:\n",
    "        loader = PyPDFLoader(path)\n",
    "        pdf_docs.extend(loader.load())\n",
    "        print(len(pdf_docs))\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading PDF {path}: {e}\")\n",
    "\n",
    "def change_pdf_doc(doc):\n",
    "    doc.metadata['type']='PDF'\n",
    "    return doc\n",
    "\n",
    "pdf_docs = list(map(change_pdf_doc, pdf_docs))\n",
    "\n",
    "print(\"=== ALL PDF docs ===)\")\n",
    "print(len(pdf_docs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c735c2b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "pptx_docs = []\n",
    "pptx_files = [\n",
    "    \"PPTX/FidesinnovaDeck-v11.pptx\"\n",
    "]\n",
    "\n",
    "for path in pptx_files:\n",
    "    try:\n",
    "        loader = UnstructuredPowerPointLoader(path)\n",
    "        pptx_docs.extend(loader.load())\n",
    "        print(f\"✅ Loaded: {path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error loading PPTX {path}: {e}\")\n",
    "\n",
    "# Add metadata\n",
    "def change_pptx_doc(doc):\n",
    "    doc.metadata['type'] = 'PPTX'\n",
    "    return doc\n",
    "\n",
    "pptx_docs = list(map(change_pptx_doc, pptx_docs))\n",
    "\n",
    "print(\"=== ALL PPTX docs ===)\")\n",
    "print(len(pptx_docs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88d77d15",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pptx_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e55ede9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Step 7: Split & Vectorize ---\n",
    "all_docs = web_docs + github_docs + youtube_docs + pdf_docs + pptx_docs\n",
    "\n",
    "splitter = RecursiveCharacterTextSplitter(chunk_size = 1000, chunk_overlap = 100)\n",
    "split_docs = splitter.split_documents(all_docs)\n",
    "\n",
    "embedding = OpenAIEmbeddings(model=\"text-embedding-3-large\")\n",
    "vectordb = Chroma(\n",
    "    collection_name=\"fides_crawled_data\",\n",
    "    embedding_function=embedding,\n",
    "    persist_directory=\"./chroma_langchain_db\"\n",
    ")\n",
    "\n",
    "vectordb.add_documents(split_docs)\n",
    "print(\"✅ All documents crawled, split, and stored in vector DB.\")\n",
    "\n",
    "print(\"=== ALL Doc.s ===)\")\n",
    "print(len(all_docs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0f70d9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(vectordb)"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
